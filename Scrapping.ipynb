{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e15c0f1",
   "metadata": {},
   "source": [
    "<h1> IMPORTING LIBRARIES <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050d263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7808408",
   "metadata": {},
   "source": [
    "<h1>  Defining the role to be searched <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be22648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINING ROLE TO SEARCH\n",
    "job = input(\"Which role do you want to search? \").lower()\n",
    "job_treated = job.replace(\" \",\"-\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b72903af",
   "metadata": {},
   "source": [
    "<h1> Web Scrapping Section <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d635705a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existem 102 vagas nesta plataforma.\n"
     ]
    }
   ],
   "source": [
    "#SETTING SITE URL\n",
    "url = f'https://www.vagas.com.br/vagas-de-{job_treated}'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.74 Safari/537.36'}\n",
    "site = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(site.content, 'html.parser')\n",
    "\n",
    "\n",
    "#LAST PAGE\n",
    "last_page = 1\n",
    "for page in soup.find_all('a',class_ = 'btMaisVagas btn'):\n",
    "    last_page = page.get('data-total').strip()\n",
    "            \n",
    "\n",
    "#NUMBER OF VACANCIES\n",
    "numero_total_anuncios = soup.find('div',class_= 'faixa clearfix').get_text()[0:4].strip()\n",
    "print(f\"Existem {numero_total_anuncios} vagas nesta plataforma.\")\n",
    "\n",
    "\n",
    "#####PAGINATION LOOP\n",
    "for i in range(1,int(last_page)+1):\n",
    "    url_pag = f'https://www.vagas.com.br/vagas-de-{job_treated}?pagina={i}'\n",
    "    site = requests.get(url_pag, 'html.parser')\n",
    "    soup = BeautifulSoup(site.content, 'html.parser')\n",
    "        \n",
    "    ######ODD\n",
    "    anuncios_impar = soup.find_all('li', class_ = 'vaga odd')\n",
    "        \n",
    "    #####EVEN\n",
    "    anuncios_par = soup.find_all('li', class_ = 'vaga even')\n",
    "        \n",
    "        \n",
    "    with open(f'vacancies-{job_treated}.csv','a',newline='', encoding = 'utf-8') as f:\n",
    "        for anuncio_impar in anuncios_impar:\n",
    "                \n",
    "            'job title'\n",
    "            job_title = anuncio_impar.find('h2',class_='cargo').get_text().strip()\n",
    "\n",
    "                \n",
    "            'company title'\n",
    "            company_title = anuncio_impar.find('span',class_ = 'emprVaga').get_text().strip()\n",
    "\n",
    "                \n",
    "            'level vacancy'\n",
    "            level_vacancy = anuncio_impar.find('span', class_='nivelVaga').get_text().strip()\n",
    "                \n",
    "            'location'\n",
    "            try:\n",
    "                location = anuncio_impar.find('span', class_= 'vaga-local').get_text().strip()\n",
    "            except:\n",
    "                location = ''\n",
    "                \n",
    "            'id vacancy'\n",
    "            id_vacancy = anuncio_impar.find('a',class_='link-detalhes-vaga').get('id').strip()\n",
    "            link_vacancy = f'https://vagas.com.br/vagas/{id_vacancy}' \n",
    "                \n",
    "            #CREATING LINES IN CSV FILE\n",
    "            line = job_title + \";\" + company_title + \";\" + level_vacancy + \";\" + location + \";\" + link_vacancy + '\\n'\n",
    "            f.write(line)\n",
    "    \n",
    "                \n",
    "        for anuncio_par in anuncios_par:\n",
    "                \n",
    "            'job title'\n",
    "            job_title = anuncio_par.find('h2',class_='cargo').get_text().strip()\n",
    "\n",
    "                \n",
    "            'company title'            \n",
    "            company_title = anuncio_par.find('span',class_ = 'emprVaga').get_text().strip()\n",
    "\n",
    "            'level vacancy'\n",
    "            level_vacancy = anuncio_par.find('span', class_='nivelVaga').get_text().strip()\n",
    "                \n",
    "            'location'\n",
    "            try:\n",
    "                location = anuncio_par.find('span', class_= 'vaga-local').get_text().strip()\n",
    "            except:\n",
    "                location = ''\n",
    "                \n",
    "            'id vacancy'\n",
    "            id_vacancy = anuncio_par.find('a',class_='link-detalhes-vaga').get('id').strip()\n",
    "            link_vacancy = f'https://vagas.com.br/vagas/{id_vacancy}'\n",
    "                \n",
    "            #CREATING LINES IN CSV FILE\n",
    "            line = job_title + \";\" + company_title + \";\" + level_vacancy + \";\" + location + \";\" + link_vacancy + '\\n'\n",
    "            f.write(line)\n",
    "\n",
    "            \n",
    "    df = pd.read_csv(f'vacancies-{job_treated}.csv',on_bad_lines='skip',  delimiter =\";\", names =  ['Cargo','Empresa','Nivel','Localidade','Link da Vaga'])   \n",
    "    df.to_excel(f'vacancies-{job_treated}.xlsx') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "802a1d6b",
   "metadata": {},
   "source": [
    "<h1> Importing data to Azure SQL <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb41b4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 37.48806548118591 seconds\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "server = 'server' #write server\n",
    "database = 'database' #write base\n",
    "username = 'username' #write username\n",
    "password = 'password' #write password\n",
    "        \n",
    "#IN THIS CASE I HAVE CONNECTED SETTLING CLOUD PARAMETERS THAT MAYBE YOU WILL CAN SETTLE DIFFERENTLY ACCORDING TO THE CLOUD PROVIDER OR THE SERVICE THAT YOU SCRAPPING REQUIRES. IN THIS SPECIFIC EXAMPLE I HAVE SETTLED EXACTLY LIKE IT CAN BE SEEING BELOW. ALSO I'M SHARING A GITHUB WITH TIPS TO SET THE PARAMETERS.\n",
    "#https://github.com/mkleehammer/pyodbc/wiki/Connecting-to-SQL-Server-from-Windows\n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+password+';ENCRYPT=Yes; fast_executemany=True;trusted_connection=no')\n",
    "cursor = cnxn.cursor()\n",
    "\n",
    "#LOOP\n",
    "for i in range(len(df)):\n",
    "    cargo = df.loc[i,'Cargo']\n",
    "    empresa = df.loc[i,'Empresa']\n",
    "    nivel = df.loc[i,'Nivel']\n",
    "    localidade = df.loc[i,'Localidade']\n",
    "    link = df.loc[i,'Link da Vaga']\n",
    "\n",
    " \n",
    "    script = '''insert into Vagascom (CargoVaga, Empresa, Senioridade, Localidade, LinkDaVaga) values ('''\n",
    "\n",
    "    data = \"'\" + cargo + \"','\" + empresa + \"','\" + nivel + \"','\" + localidade + \"','\" + link + \"')\"        \n",
    "\n",
    "    query = script + data  \n",
    "    \n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        cursor.commit()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "cursor.close()\n",
    "\n",
    "tempoExec = time.time() - t1\n",
    "print(\"Execution Time: {} seconds\".format(tempoExec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
